# Functional Analysis of TargetDatabase

_**This demo guides you how to analyze the pathway profile annotated from humman2 against 7 target databases.**_  

Target database inclues 7 types: 

1. acetate

2. butyrate

3. formate

4. propionate

5. card

6. cazy

7. vfdb

![FlowChart_KEGG](./flowcharts/FlowChart_TargetDB.jpg)

**The analysis of the 7 types of target databases are pretty much the same, here we use CARD database as an example.**

---

## Environment setup

```{r setup, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Load requeired packages
library(tibble)
library(phyloseq)
library(stringr)
library(xviz)
library(reshape2)
library(magrittr)
library(dplyr)
library(pathview)

## Load functions
source("/share/projects/SOP/Functional_Analysis/Tongbangzhuo/Phase1/Kegg/Scripts/R/ultility.R")
```

---

## Pipeline file processing

_As described in the introduction chapter, **a cohort containing 8 MGS samples of 4 patients from 2 groups in MAFLD project** would be used as demo data in this tutorial._  

### Merge sample files (Target db)

Here we need to merge all CARD data from 8 samples into one profile table with the merge script from Humann2 **in Bash**. But if you have merged the sample data already, please skip this chunk and jump to [Data loading](#data-loading-target-db).

```markdown

docker run -i --rm -u $(id -u):$(id -g) -v /share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/:/in harbor.xbiome.com/xbiome/environments/humann2:2.8.1-2b8c5c3 bash -c "merge_metaphlan_tables.py /in/PipelineOutput/*/humann2_card/*_genefamilies.tsv > /in/Card/merged_card_profile.tsv"

```

### Split strain info (Target db)

Output profile from Humann2 pipeline contains strain information, we need to split the profile file into two files **in Bash**. But if you have splitted the sample data already, please skip this chunk and jump to [Data loading](#data-loading-target-db).

- unstratified profile file
- stratified profile file

```markdown

grep -v "s_" /share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/Card/merged_card_profile.tsv >  /share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/Card/merged_card_profile_unstratified.tsv

grep -E "s_|ID" /share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/Metacyc/merged_metacyc_profile.tsv >  /share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/Card/merged_card_profile_stratified.tsv

```

---

## Data loading (Target db)

_**Since the format of pathway profile annotated in 7 target databases are almost identical, We use card data as an example.**_

Same as kegg pathway data, we rescale data at the begining of analysis to reduce the differences of sequencing depth across all samples.

_**Read in card data**_

```{r rescale card data}
## Read in merged card profile data

merged_card_profile <- read.table('/share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/Card/merged_card_profile_unstratified.tsv',
                                  sep = '\t', header = TRUE, check.names = FALSE, na.strings = '',comment.char = '', quote = '')

colnames(merged_card_profile) %<>% str_remove_all(., '_.+')

# ## Rename entry name, keep ARO number
# merged_card_profile$ID %<>% str_replace_all(., '.+(ARO:[0-9]+)\\|(.+)_\\[.+\\]', '\\1|\\2')
# 
# head(merged_card_profile, n = 2)

## Read in metadata (Group information)
metadata <- read.table('/share/projects/SOP/Functional_Analysis/Tongbangzhuo/Demodata/metadata.xls', check.names = FALSE, header = TRUE)

metadata %<>% column_to_rownames('SeqID')
```

---

## Data preprocessing (Target db)

### Transforming data (Target db)

```{r TSS transformation}
rescaled_merged_card_profile <- merged_card_profile %>% column_to_rownames('ID') %>% apply(., 2, function(x) x/sum(x)) %>% as.data.frame()

head(rescaled_merged_card_profile, n = 2)
dim(rescaled_merged_card_profile)
```

### Remove unppaed pathways (Target db)

```{r remove unmapped features}
## In this chunk, we remove the umapped row in rescaled profile table because we are not able to intepret UNMAPPED entry.

card_profile <- rescaled_merged_card_profile[grep("UNMAPPED", rownames(rescaled_merged_card_profile), invert = TRUE), ]

dim(card_profile)
```

### Aggregate low abundance data

In this chunck, we aggregate low abundance features to one row.  
_**1e-12 is an empirical threshold fot filtering low abundance feature. According to published paper [Obese Individuals with and without Type 2 Diabetes Show Different Gut Microbial Functional Capacity and Composition](https://doi.org/10.1016/j.chom.2019.07.004), pathway with top 50% mean abundance and top 50% variance are left. But in MaAsLin2ï¼Œpathway with abundance less than 10-10 are filtered by default.**_  

Note: Run [Transforming data](#transforming-data-target-db) and [Remove unmapped pathways](#remove-unppaed-pathways-target-db) before running this chunk!

```{r filter}

Filtered_card_profile <- aggregate_low_abundance(input_data = card_profile,
                                                           threshold = 1e-12) ## threshold should be modified based on your on study

dim(Filtered_card_profile)

```

---

## Standard analysis

**Note: All chunks in [Data preprocessing](#data-preprocessing-target-db) should be excuted before doing analysis in this chunk.**

### Compositional barplot

```{r Compositional barplot, fig.width = 6, fig.height = 9}
## In this chunk, we construct stacked pathway barplot to depict the pathway composition of samples, we use function plot_stacked_bar from xviz to plot.
## In case there are too much entries, we use parameter "collapse" in plot_stacked_bar function to integrate entries whose abundance are below given threshold into "Others".
## Note: Adjust your graph size to show complete graph.

compositional_plt <- xviz::plot_stacked_bar(otu_table = Filtered_card_profile %>% t() %>% as.data.frame(),
                 metadata = metadata, collapse = 0.01) + theme(axis.text.x = element_text(vjust = 1))

compositional_plt
```

### Beta diversity

```{r Beta diversity}
## In this chunk, we inherit the concept of Beta diversity of microbial taxa data and apply it to pathway data to explore the similarity between samples.

## construct phyloseq for beta diversity analysis

tmp_phyloseq <- phyloseq(otu_table(Filtered_card_profile, taxa_are_rows = TRUE),
                         sample_data(metadata))


## PCoA plot
PCOA_plot <- xviz::plot_beta_diversity(phyloseq = tmp_phyloseq,
                                       feature = 'Group',
                                       method = 'bray',
                                       label = TRUE)
print(PCOA_plot)


## PERMANOVA test & beta dispersion test
## We use PERMANOVA test to check the differences of function composition among different groups. Additionally, we also take homogeneity of group variance into consideration.

dispersion_permanova_res <- run_permanova_betadisp(physeq = tmp_phyloseq,
                                                   vars = 'Group'
                                                   )

dispersion_permanova_res

```

---

## Differential analysis (DA)

### Filter low prevalence pathway (DA)

Low prevalence pathways are pathways only occur in minor samples.
In this chunk, we would remove pathways apperaing in less than max(2 , 5% of samples) from data set before doing analysis. **Remember to run [Data preprocessing](#data-preprocessing-target-db) before running this chunk!**  

```{r Filter low prevalence pathway}

print(paste0(nrow(Filtered_card_profile), ' entries before filtering low prevalence data'))

Filtered_card_profile <- filter_prevalence(otu_table = Filtered_card_profile,
                  threshold = 0.05,
                  taxa_are_rows = TRUE
                  )

head(Filtered_card_profile, n =2)

print(paste0(nrow(Filtered_card_profile), ' entries After filtering low prevalence data'))

```

### DA with LM

**Note: Please [Filter low prevalence pathway](#filter-low-prevalence-pathway-da) before DA.**

```{r DA}
## In this chunk, you would be using logistic regression model to find pathways that are significantly enriched in certain group.

## Due to the nature of compositional data, we cannot apply linear models to compositional data directly. 
## Transformation of relative abundance data should be carried out before feeding the data to LM.
## Here, we add a very small value (1e-12) to the pathway profile table to avoid genrating NA during transformation, then use logit transformation to transform data. And eventually we apply LM to the transformed data

## Adding small value to the profile table (The value is arbitrary).

DA_card_profile <- Filtered_card_profile + 1e-12

## Reshape profile data table and use logit transformation.

DA_card_profile <- DA_card_profile %>% t() %>% as.data.frame() %>% rownames_to_column('SeqID') %>% as.data.frame()
DA_metadata <- metadata %>% rownames_to_column('SeqID') %>% as.data.frame()

## Reshape dataframe into long table
DA_input <- merge(DA_card_profile, DA_metadata, by='SeqID') %>% reshape2::melt(value.name = 'RA',
                                                                                         variable.name = 'PathwayIDs')

## Logit transformation
DA_input %<>% mutate(RA_logit = log(RA/(1-RA)))

## Fit data to LM
## Loop over each pathway in two groups
LM_res <- DA_input %>%  split(.$PathwayIDs) %>% lapply(., function(x){
  gml_res_summary <- lm(data = x, formula = RA_logit ~ Group) %>% summary() %>% .$coefficients %>% as.matrix() %>% as.data.frame() %>% rownames_to_column(var = "Factors")
  }
)

## Merge all result in one table
LM_res <- LM_res %>% data.table::rbindlist(idcol = "PathwayID") %>% filter(Factors != "(Intercept)")

## Adjust p value using p.adjust function from stats package, you could choose different adjust method.
LM_res %<>% mutate(adjust.p  = stats::p.adjust(.$`Pr(>|t|)`,
                                               method = 'BH'))

## Calculate effect size (Odds ratio) of each feature
LM_res %<>% mutate(OR = exp(Estimate)) %>% as.data.frame()

head(LM_res)

```

### Show DA result with volcano plot

```{r visualize DA result by volcano plot}
## Plot volcano plot to show effect size (x-axis) and p value (y-axis) of pathways.
## Here we only tend to hightlight pathways that satisfy adjust.p < 0.05 and (OR < 0.2 | OR > 0.5) at the same time.
## You can nevertheless choose different threshold accroding to your own data.

volcano_plot <- LM_res %>% mutate(p.log = -log10(`Pr(>|t|)`), log10OR = log10(OR)) %>%
    ggplot(aes(x = log10OR, y = p.log)) +
    geom_point(size = 0.5) +
    geom_point(size = 0.5, color = "red", data = . %>% filter(`Pr(>|t|)` < 0.05 & (OR < 0.2 | OR > 0.5))) + 
    theme_bw() + 
    geom_vline(xintercept = log10(c(0.05, 0.1, 0.2, 0.5, 1, 2)), size = 0.05, color = "grey") +
    geom_hline(yintercept = -log10(c(0.7)), size = 0.05, color = "grey") +
    theme(aspect.ratio = 1,
          panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank()
          ) +
    labs(x = "Estimated Odds Ratio", y = "FDR p-values(-log10)")

print(volcano_plot)

```

---

## Session info

```{r session info target db}
devtools::session_info()
```

